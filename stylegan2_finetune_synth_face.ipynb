{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt1OfADw43oSxpPwRmkZp1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdelta/ImageGen/blob/main/stylegan2_finetune_synth_face.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i18v-FoPKu0P",
        "outputId": "ffbbd0ac-5539-4c77-d8e6-81a6c68d5404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbsLKrW85ISu",
        "outputId": "8892e410-39dc-4d5c-f7eb-7d3adb4fb10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n",
            "Collecting pyspng\n",
            "  Downloading pyspng-0.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[K     |████████████████████████████████| 205 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 77.7 MB/s \n",
            "\u001b[?25hCollecting imageio-ffmpeg==0.4.3\n",
            "  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pyspng) (1.21.6)\n",
            "Installing collected packages: pyspng, ninja, imageio-ffmpeg\n",
            "Successfully installed imageio-ffmpeg-0.4.3 ninja-1.11.1 pyspng-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sdelta/stylegan2-ada-pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlazkfAZ5SfS",
        "outputId": "6429586d-043d-46fc-a73a-e690a599f3cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan2-ada-pytorch'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 148 (delta 10), reused 0 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (148/148), 1.13 MiB | 8.96 MiB/s, done.\n",
            "Resolving deltas: 100% (67/67), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/transfer-learning-source-nets/ffhq-res256-mirror-paper256-noaug.pkl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYdu-X-YkRIU",
        "outputId": "f3dc0ea4-96be-437c-f15d-90a486907b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-08 00:44:05--  https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/transfer-learning-source-nets/ffhq-res256-mirror-paper256-noaug.pkl\n",
            "Resolving nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)... 13.249.85.31, 13.249.85.118, 13.249.85.23, ...\n",
            "Connecting to nvlabs-fi-cdn.nvidia.com (nvlabs-fi-cdn.nvidia.com)|13.249.85.31|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 295744285 (282M) [binary/octet-stream]\n",
            "Saving to: ‘ffhq-res256-mirror-paper256-noaug.pkl’\n",
            "\n",
            "ffhq-res256-mirror- 100%[===================>] 282.04M   101MB/s    in 2.8s    \n",
            "\n",
            "2022-12-08 00:44:09 (101 MB/s) - ‘ffhq-res256-mirror-paper256-noaug.pkl’ saved [295744285/295744285]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/datasets/ffhq_256/ffhq_glasses.zip ./"
      ],
      "metadata": {
        "id": "_mj9MfXDkUhD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFtl-xc6qQ5e",
        "outputId": "3481dc84-b6f0-4c5c-cb86-20457951568e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive\t\t  ffhq-res256-mirror-paper256-noaug.pkl  stylegan2-ada-pytorch\n",
            "ffhq_glasses.zip  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python stylegan2-ada-pytorch/train.py --outdir=drive/MyDrive/stylegan_finetuning --data=ffhq_glasses.zip \\\n",
        "    --mirror=1 --gpus=1 --resume=ffhq-res256-mirror-paper256-noaug.pkl --kimg=1500 --freezed=10 --freezed_mapping=True --dry-run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqSSP0b06pqb",
        "outputId": "6150c63a-5c2d-460a-e7ff-25853f5d6fd0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 50,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"synthetic_256x256.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 100000,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 256\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2,\n",
            "      \"trainable\": false\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 16384,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 10\n",
            "    },\n",
            "    \"mapping_kwargs\": {\n",
            "      \"trainable\": false\n",
            "    },\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 16384,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.8192\n",
            "  },\n",
            "  \"total_kimg\": 1500,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"ema_rampup\": null,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"ffhq-res256-mirror-paper256-noaug.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"drive/MyDrive/stylegan_finetuning/00008-synthetic_256x256-mirror-auto1-kimg1500-resumecustom-freezed10-freezed_mapping\"\n",
            "}\n",
            "\n",
            "Output directory:   drive/MyDrive/stylegan_finetuning/00008-synthetic_256x256-mirror-auto1-kimg1500-resumecustom-freezed10-freezed_mapping\n",
            "Training data:      synthetic_256x256.zip\n",
            "Training duration:  1500 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   100000\n",
            "Image resolution:   256\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "\n",
            "Num images:  200000\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Resuming from \"ffhq-res256-mirror-paper256-noaug.pkl\"\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Generator             Parameters  Buffers  Output shape         Datatype\n",
            "---                   ---         ---      ---                  ---     \n",
            "mapping.fc0           -           262656   [16, 512]            float32 \n",
            "mapping.fc1           -           262656   [16, 512]            float32 \n",
            "mapping               -           512      [16, 14, 512]        float32 \n",
            "synthesis.b4.conv1    2622465     32       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4.torgb    264195      -        [16, 3, 4, 4]        float32 \n",
            "synthesis.b4:0        8192        16       [16, 512, 4, 4]      float32 \n",
            "synthesis.b4:1        -           -        [16, 512, 4, 4]      float32 \n",
            "synthesis.b8.conv0    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.conv1    2622465     80       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8.torgb    264195      -        [16, 3, 8, 8]        float32 \n",
            "synthesis.b8:0        -           16       [16, 512, 8, 8]      float32 \n",
            "synthesis.b8:1        -           -        [16, 512, 8, 8]      float32 \n",
            "synthesis.b16.conv0   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.conv1   2622465     272      [16, 512, 16, 16]    float32 \n",
            "synthesis.b16.torgb   264195      -        [16, 3, 16, 16]      float32 \n",
            "synthesis.b16:0       -           16       [16, 512, 16, 16]    float32 \n",
            "synthesis.b16:1       -           -        [16, 512, 16, 16]    float32 \n",
            "synthesis.b32.conv0   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.conv1   2622465     1040     [16, 512, 32, 32]    float16 \n",
            "synthesis.b32.torgb   264195      -        [16, 3, 32, 32]      float16 \n",
            "synthesis.b32:0       -           16       [16, 512, 32, 32]    float16 \n",
            "synthesis.b32:1       -           -        [16, 512, 32, 32]    float32 \n",
            "synthesis.b64.conv0   1442561     4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.conv1   721409      4112     [16, 256, 64, 64]    float16 \n",
            "synthesis.b64.torgb   132099      -        [16, 3, 64, 64]      float16 \n",
            "synthesis.b64:0       -           16       [16, 256, 64, 64]    float16 \n",
            "synthesis.b64:1       -           -        [16, 256, 64, 64]    float32 \n",
            "synthesis.b128.conv0  426369      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.conv1  213249      16400    [16, 128, 128, 128]  float16 \n",
            "synthesis.b128.torgb  66051       -        [16, 3, 128, 128]    float16 \n",
            "synthesis.b128:0      -           16       [16, 128, 128, 128]  float16 \n",
            "synthesis.b128:1      -           -        [16, 128, 128, 128]  float32 \n",
            "synthesis.b256.conv0  139457      65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.conv1  69761       65552    [16, 64, 256, 256]   float16 \n",
            "synthesis.b256.torgb  33027       -        [16, 3, 256, 256]    float16 \n",
            "synthesis.b256:0      -           16       [16, 64, 256, 256]   float16 \n",
            "synthesis.b256:1      -           -        [16, 64, 256, 256]   float32 \n",
            "---                   ---         ---      ---                  ---     \n",
            "Total                 22666210    700880   -                    -       \n",
            "\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   -           272      [16, 64, 256, 256]   float16 \n",
            "b256.skip      -           8208     [16, 128, 128, 128]  float16 \n",
            "b256.conv0     -           36944    [16, 64, 256, 256]   float16 \n",
            "b256.conv1     -           73872    [16, 128, 128, 128]  float16 \n",
            "b256           -           16       [16, 128, 128, 128]  float16 \n",
            "b128.skip      -           32784    [16, 256, 64, 64]    float16 \n",
            "b128.conv0     -           147600   [16, 128, 128, 128]  float16 \n",
            "b128.conv1     -           295184   [16, 256, 64, 64]    float16 \n",
            "b128           -           16       [16, 256, 64, 64]    float16 \n",
            "b64.skip       -           131088   [16, 512, 32, 32]    float16 \n",
            "b64.conv0      -           590096   [16, 256, 64, 64]    float16 \n",
            "b64.conv1      -           1180176  [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          21505025    2496480  -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "2022-12-09 01:04:12.977056: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "Training for 1500 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 1m 41s       sec/tick 11.0    sec/kimg 690.32  maintenance 90.0   cpumem 6.47   gpumem 17.54  augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 135.3177039078798}, \"metric\": \"fid50k_full\", \"total_time\": 449.63521099090576, \"total_time_str\": \"7m 30s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1670548328.7253985}\n",
            "tick 1     kimg 4.0      time 10m 17s      sec/tick 53.0    sec/kimg 13.24   maintenance 462.7  cpumem 7.32   gpumem 9.56   augment 0.038\n",
            "tick 2     kimg 8.0      time 11m 10s      sec/tick 53.2    sec/kimg 13.29   maintenance 0.0    cpumem 7.32   gpumem 4.76   augment 0.077\n",
            "tick 3     kimg 12.0     time 12m 03s      sec/tick 52.9    sec/kimg 13.22   maintenance 0.0    cpumem 7.32   gpumem 4.83   augment 0.111\n",
            "tick 4     kimg 16.0     time 12m 56s      sec/tick 53.2    sec/kimg 13.30   maintenance 0.0    cpumem 7.32   gpumem 4.81   augment 0.147\n",
            "tick 5     kimg 20.0     time 13m 49s      sec/tick 53.2    sec/kimg 13.31   maintenance 0.0    cpumem 7.32   gpumem 4.83   augment 0.182\n",
            "tick 6     kimg 24.0     time 14m 42s      sec/tick 53.1    sec/kimg 13.27   maintenance 0.0    cpumem 7.32   gpumem 4.84   augment 0.209\n",
            "tick 7     kimg 28.0     time 15m 36s      sec/tick 53.3    sec/kimg 13.32   maintenance 0.0    cpumem 7.32   gpumem 4.82   augment 0.235\n",
            "tick 8     kimg 32.0     time 16m 29s      sec/tick 53.4    sec/kimg 13.36   maintenance 0.0    cpumem 7.32   gpumem 4.82   augment 0.258\n",
            "tick 9     kimg 36.0     time 17m 22s      sec/tick 53.2    sec/kimg 13.30   maintenance 0.1    cpumem 7.32   gpumem 4.83   augment 0.275\n",
            "tick 10    kimg 40.0     time 18m 16s      sec/tick 53.3    sec/kimg 13.33   maintenance 0.0    cpumem 7.32   gpumem 4.94   augment 0.292\n",
            "tick 11    kimg 44.0     time 19m 09s      sec/tick 53.1    sec/kimg 13.27   maintenance 0.0    cpumem 7.32   gpumem 4.86   augment 0.305\n",
            "tick 12    kimg 48.0     time 20m 02s      sec/tick 53.4    sec/kimg 13.35   maintenance 0.0    cpumem 7.32   gpumem 4.83   augment 0.312\n",
            "tick 13    kimg 52.0     time 20m 55s      sec/tick 53.3    sec/kimg 13.33   maintenance 0.0    cpumem 7.32   gpumem 4.87   augment 0.316\n",
            "tick 14    kimg 56.0     time 21m 49s      sec/tick 53.2    sec/kimg 13.30   maintenance 0.0    cpumem 7.32   gpumem 4.86   augment 0.323\n",
            "tick 15    kimg 60.0     time 22m 42s      sec/tick 53.2    sec/kimg 13.29   maintenance 0.0    cpumem 7.32   gpumem 4.86   augment 0.331\n",
            "tick 16    kimg 64.0     time 23m 35s      sec/tick 53.1    sec/kimg 13.26   maintenance 0.0    cpumem 7.32   gpumem 4.84   augment 0.341\n",
            "tick 17    kimg 68.0     time 24m 28s      sec/tick 53.0    sec/kimg 13.25   maintenance 0.1    cpumem 7.32   gpumem 4.86   augment 0.347\n",
            "tick 18    kimg 72.0     time 25m 21s      sec/tick 53.4    sec/kimg 13.34   maintenance 0.0    cpumem 7.32   gpumem 4.85   augment 0.351\n",
            "tick 19    kimg 76.0     time 26m 14s      sec/tick 53.0    sec/kimg 13.25   maintenance 0.0    cpumem 7.32   gpumem 4.85   augment 0.346\n",
            "tick 20    kimg 80.0     time 27m 08s      sec/tick 53.4    sec/kimg 13.35   maintenance 0.0    cpumem 7.32   gpumem 4.86   augment 0.344\n",
            "tick 21    kimg 84.0     time 28m 01s      sec/tick 53.2    sec/kimg 13.29   maintenance 0.0    cpumem 7.32   gpumem 4.88   augment 0.344\n",
            "tick 22    kimg 88.0     time 28m 54s      sec/tick 53.4    sec/kimg 13.34   maintenance 0.0    cpumem 7.32   gpumem 4.88   augment 0.338\n",
            "tick 23    kimg 92.0     time 29m 47s      sec/tick 53.0    sec/kimg 13.26   maintenance 0.0    cpumem 7.32   gpumem 4.91   augment 0.344\n",
            "tick 24    kimg 96.0     time 30m 41s      sec/tick 53.2    sec/kimg 13.30   maintenance 0.0    cpumem 7.32   gpumem 4.87   augment 0.339\n",
            "tick 25    kimg 100.0    time 31m 34s      sec/tick 53.0    sec/kimg 13.26   maintenance 0.1    cpumem 7.32   gpumem 4.85   augment 0.340\n",
            "tick 26    kimg 104.0    time 32m 27s      sec/tick 53.1    sec/kimg 13.29   maintenance 0.0    cpumem 7.32   gpumem 4.84   augment 0.346\n",
            "tick 27    kimg 108.0    time 33m 19s      sec/tick 52.7    sec/kimg 13.18   maintenance 0.0    cpumem 7.32   gpumem 4.88   augment 0.345\n",
            "tick 28    kimg 112.0    time 34m 13s      sec/tick 53.3    sec/kimg 13.33   maintenance 0.0    cpumem 7.32   gpumem 4.86   augment 0.338\n",
            "tick 29    kimg 116.0    time 35m 06s      sec/tick 53.1    sec/kimg 13.27   maintenance 0.0    cpumem 7.32   gpumem 4.89   augment 0.335\n",
            "tick 30    kimg 120.0    time 36m 00s      sec/tick 53.8    sec/kimg 13.44   maintenance 0.0    cpumem 7.32   gpumem 4.89   augment 0.341\n",
            "tick 31    kimg 124.0    time 36m 53s      sec/tick 53.1    sec/kimg 13.28   maintenance 0.0    cpumem 7.32   gpumem 4.85   augment 0.335\n",
            "tick 32    kimg 128.0    time 37m 46s      sec/tick 53.2    sec/kimg 13.31   maintenance 0.0    cpumem 7.32   gpumem 4.88   augment 0.342\n",
            "tick 33    kimg 132.0    time 38m 39s      sec/tick 53.2    sec/kimg 13.29   maintenance 0.1    cpumem 7.32   gpumem 4.86   augment 0.344\n",
            "tick 34    kimg 136.0    time 39m 33s      sec/tick 53.6    sec/kimg 13.40   maintenance 0.0    cpumem 7.32   gpumem 4.90   augment 0.349\n",
            "tick 35    kimg 140.0    time 40m 26s      sec/tick 53.2    sec/kimg 13.29   maintenance 0.0    cpumem 7.32   gpumem 4.84   augment 0.346\n",
            "tick 36    kimg 144.0    time 41m 19s      sec/tick 53.3    sec/kimg 13.32   maintenance 0.0    cpumem 7.32   gpumem 4.90   augment 0.342\n",
            "tick 37    kimg 148.0    time 42m 13s      sec/tick 53.1    sec/kimg 13.29   maintenance 0.0    cpumem 7.32   gpumem 4.86   augment 0.348\n",
            "tick 38    kimg 152.0    time 43m 06s      sec/tick 53.2    sec/kimg 13.30   maintenance 0.0    cpumem 7.32   gpumem 4.88   augment 0.342\n",
            "tick 39    kimg 156.0    time 43m 59s      sec/tick 53.4    sec/kimg 13.34   maintenance 0.0    cpumem 7.32   gpumem 4.89   augment 0.344\n",
            "tick 40    kimg 160.0    time 44m 52s      sec/tick 53.0    sec/kimg 13.25   maintenance 0.0    cpumem 7.32   gpumem 4.85   augment 0.348\n",
            "tick 41    kimg 164.0    time 45m 45s      sec/tick 52.8    sec/kimg 13.20   maintenance 0.1    cpumem 7.32   gpumem 4.85   augment 0.346\n",
            "tick 42    kimg 168.0    time 46m 38s      sec/tick 53.1    sec/kimg 13.27   maintenance 0.0    cpumem 7.32   gpumem 4.85   augment 0.347\n",
            "tick 43    kimg 172.0    time 47m 31s      sec/tick 52.6    sec/kimg 13.14   maintenance 0.0    cpumem 7.32   gpumem 4.87   augment 0.346\n",
            "tick 44    kimg 176.0    time 48m 24s      sec/tick 53.3    sec/kimg 13.32   maintenance 0.0    cpumem 7.32   gpumem 4.87   augment 0.352\n",
            "tick 45    kimg 180.0    time 49m 17s      sec/tick 52.9    sec/kimg 13.23   maintenance 0.0    cpumem 7.32   gpumem 4.90   augment 0.355\n",
            "tick 46    kimg 184.0    time 50m 10s      sec/tick 53.1    sec/kimg 13.27   maintenance 0.0    cpumem 7.32   gpumem 4.89   augment 0.351\n",
            "tick 47    kimg 188.0    time 51m 03s      sec/tick 53.0    sec/kimg 13.24   maintenance 0.0    cpumem 7.32   gpumem 4.85   augment 0.351\n",
            "tick 48    kimg 192.0    time 51m 56s      sec/tick 53.0    sec/kimg 13.24   maintenance 0.0    cpumem 7.32   gpumem 4.86   augment 0.350\n",
            "tick 49    kimg 196.0    time 52m 49s      sec/tick 52.8    sec/kimg 13.20   maintenance 0.1    cpumem 7.32   gpumem 4.85   augment 0.346\n",
            "tick 50    kimg 200.0    time 53m 42s      sec/tick 52.9    sec/kimg 13.22   maintenance 0.0    cpumem 7.32   gpumem 4.86   augment 0.350\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 24.6550867814949}, \"metric\": \"fid50k_full\", \"total_time\": 304.0182349681854, \"total_time_str\": \"5m 04s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000200.pkl\", \"timestamp\": 1670551306.51149}\n",
            "tick 51    kimg 204.0    time 59m 55s      sec/tick 53.1    sec/kimg 13.28   maintenance 319.8  cpumem 7.80   gpumem 4.88   augment 0.354\n",
            "tick 52    kimg 208.0    time 1h 00m 48s   sec/tick 53.3    sec/kimg 13.32   maintenance 0.0    cpumem 7.80   gpumem 4.89   augment 0.358\n",
            "tick 53    kimg 212.0    time 1h 01m 41s   sec/tick 53.1    sec/kimg 13.27   maintenance 0.0    cpumem 7.80   gpumem 4.88   augment 0.350\n",
            "tick 54    kimg 216.0    time 1h 02m 34s   sec/tick 53.1    sec/kimg 13.27   maintenance 0.0    cpumem 7.80   gpumem 4.84   augment 0.344\n",
            "tick 55    kimg 220.0    time 1h 03m 27s   sec/tick 53.2    sec/kimg 13.30   maintenance 0.0    cpumem 7.80   gpumem 4.86   augment 0.338\n",
            "tick 56    kimg 224.0    time 1h 04m 21s   sec/tick 53.3    sec/kimg 13.33   maintenance 0.0    cpumem 7.80   gpumem 4.88   augment 0.332\n",
            "tick 57    kimg 228.0    time 1h 05m 14s   sec/tick 53.0    sec/kimg 13.24   maintenance 0.1    cpumem 7.80   gpumem 4.85   augment 0.343\n",
            "tick 58    kimg 232.0    time 1h 06m 07s   sec/tick 53.3    sec/kimg 13.33   maintenance 0.0    cpumem 7.80   gpumem 4.87   augment 0.345\n",
            "tick 59    kimg 236.0    time 1h 07m 00s   sec/tick 53.0    sec/kimg 13.26   maintenance 0.0    cpumem 7.80   gpumem 4.87   augment 0.342\n",
            "tick 60    kimg 240.0    time 1h 07m 53s   sec/tick 53.4    sec/kimg 13.35   maintenance 0.0    cpumem 7.80   gpumem 4.85   augment 0.342\n",
            "tick 61    kimg 244.0    time 1h 08m 47s   sec/tick 54.0    sec/kimg 13.50   maintenance 0.0    cpumem 7.80   gpumem 4.85   augment 0.333\n",
            "tick 62    kimg 248.0    time 1h 09m 41s   sec/tick 53.4    sec/kimg 13.36   maintenance 0.0    cpumem 7.80   gpumem 4.91   augment 0.332\n",
            "tick 63    kimg 252.0    time 1h 10m 34s   sec/tick 53.5    sec/kimg 13.37   maintenance 0.0    cpumem 7.80   gpumem 4.85   augment 0.332\n",
            "tick 64    kimg 256.0    time 1h 11m 28s   sec/tick 53.5    sec/kimg 13.37   maintenance 0.0    cpumem 7.80   gpumem 4.86   augment 0.326\n",
            "tick 65    kimg 260.0    time 1h 12m 21s   sec/tick 53.3    sec/kimg 13.32   maintenance 0.1    cpumem 7.80   gpumem 4.85   augment 0.326\n",
            "tick 66    kimg 264.0    time 1h 13m 15s   sec/tick 53.5    sec/kimg 13.36   maintenance 0.0    cpumem 7.80   gpumem 4.85   augment 0.324\n",
            "tick 67    kimg 268.0    time 1h 14m 08s   sec/tick 53.3    sec/kimg 13.33   maintenance 0.0    cpumem 7.80   gpumem 4.86   augment 0.324\n",
            "tick 68    kimg 272.0    time 1h 15m 01s   sec/tick 53.3    sec/kimg 13.32   maintenance 0.0    cpumem 7.80   gpumem 4.85   augment 0.330\n",
            "tick 69    kimg 276.0    time 1h 15m 55s   sec/tick 53.3    sec/kimg 13.32   maintenance 0.0    cpumem 7.80   gpumem 4.89   augment 0.324\n",
            "tick 70    kimg 280.0    time 1h 16m 48s   sec/tick 53.4    sec/kimg 13.35   maintenance 0.0    cpumem 7.80   gpumem 4.84   augment 0.330\n",
            "tick 71    kimg 284.0    time 1h 17m 41s   sec/tick 53.3    sec/kimg 13.33   maintenance 0.0    cpumem 7.80   gpumem 4.87   augment 0.320\n",
            "tick 72    kimg 288.0    time 1h 18m 35s   sec/tick 53.3    sec/kimg 13.32   maintenance 0.0    cpumem 7.80   gpumem 4.89   augment 0.336\n",
            "tick 73    kimg 292.0    time 1h 19m 28s   sec/tick 53.3    sec/kimg 13.33   maintenance 0.1    cpumem 7.80   gpumem 4.85   augment 0.340\n",
            "tick 74    kimg 296.0    time 1h 20m 21s   sec/tick 53.3    sec/kimg 13.34   maintenance 0.0    cpumem 7.80   gpumem 4.86   augment 0.344\n",
            "tick 75    kimg 300.0    time 1h 21m 15s   sec/tick 53.1    sec/kimg 13.27   maintenance 0.0    cpumem 7.80   gpumem 4.85   augment 0.339\n",
            "tick 76    kimg 304.0    time 1h 22m 08s   sec/tick 53.9    sec/kimg 13.47   maintenance 0.0    cpumem 7.80   gpumem 4.90   augment 0.339\n",
            "tick 77    kimg 308.0    time 1h 23m 02s   sec/tick 53.6    sec/kimg 13.39   maintenance 0.0    cpumem 7.80   gpumem 4.89   augment 0.335\n",
            "tick 78    kimg 312.0    time 1h 23m 55s   sec/tick 52.8    sec/kimg 13.21   maintenance 0.0    cpumem 7.80   gpumem 4.86   augment 0.341\n",
            "tick 79    kimg 316.0    time 1h 24m 48s   sec/tick 52.8    sec/kimg 13.19   maintenance 0.0    cpumem 7.80   gpumem 4.87   augment 0.335\n",
            "tick 80    kimg 320.0    time 1h 25m 40s   sec/tick 52.7    sec/kimg 13.16   maintenance 0.0    cpumem 7.80   gpumem 4.85   augment 0.335\n",
            "tick 81    kimg 324.0    time 1h 26m 33s   sec/tick 52.4    sec/kimg 13.10   maintenance 0.1    cpumem 7.80   gpumem 4.86   augment 0.331\n",
            "tick 82    kimg 328.0    time 1h 27m 26s   sec/tick 52.8    sec/kimg 13.20   maintenance 0.0    cpumem 7.80   gpumem 4.85   augment 0.337\n",
            "tick 83    kimg 332.0    time 1h 28m 18s   sec/tick 52.7    sec/kimg 13.18   maintenance 0.0    cpumem 7.80   gpumem 4.86   augment 0.332\n",
            "tick 84    kimg 336.0    time 1h 29m 11s   sec/tick 52.8    sec/kimg 13.20   maintenance 0.0    cpumem 7.80   gpumem 4.86   augment 0.333\n",
            "tick 85    kimg 340.0    time 1h 30m 04s   sec/tick 52.6    sec/kimg 13.15   maintenance 0.0    cpumem 7.80   gpumem 4.87   augment 0.333\n",
            "tick 86    kimg 344.0    time 1h 30m 57s   sec/tick 52.8    sec/kimg 13.21   maintenance 0.0    cpumem 7.80   gpumem 4.88   augment 0.328\n",
            "tick 87    kimg 348.0    time 1h 31m 49s   sec/tick 52.8    sec/kimg 13.20   maintenance 0.0    cpumem 7.80   gpumem 4.87   augment 0.326\n",
            "tick 88    kimg 352.0    time 1h 32m 42s   sec/tick 52.7    sec/kimg 13.18   maintenance 0.0    cpumem 7.80   gpumem 4.87   augment 0.332\n",
            "tick 89    kimg 356.0    time 1h 33m 35s   sec/tick 52.6    sec/kimg 13.15   maintenance 0.1    cpumem 7.80   gpumem 4.85   augment 0.339\n",
            "tick 90    kimg 360.0    time 1h 34m 28s   sec/tick 53.0    sec/kimg 13.24   maintenance 0.0    cpumem 7.80   gpumem 4.91   augment 0.342\n",
            "tick 91    kimg 364.0    time 1h 35m 20s   sec/tick 52.5    sec/kimg 13.12   maintenance 0.0    cpumem 7.80   gpumem 4.88   augment 0.342\n",
            "tick 92    kimg 368.0    time 1h 36m 13s   sec/tick 52.7    sec/kimg 13.18   maintenance 0.0    cpumem 7.80   gpumem 4.87   augment 0.343\n",
            "tick 93    kimg 372.0    time 1h 37m 06s   sec/tick 52.6    sec/kimg 13.16   maintenance 0.0    cpumem 7.80   gpumem 4.86   augment 0.340\n",
            "tick 94    kimg 376.0    time 1h 37m 58s   sec/tick 52.6    sec/kimg 13.16   maintenance 0.0    cpumem 7.80   gpumem 4.88   augment 0.342\n",
            "tick 95    kimg 380.0    time 1h 38m 51s   sec/tick 52.6    sec/kimg 13.15   maintenance 0.0    cpumem 7.80   gpumem 4.89   augment 0.331\n",
            "tick 96    kimg 384.0    time 1h 39m 44s   sec/tick 52.9    sec/kimg 13.23   maintenance 0.0    cpumem 7.80   gpumem 4.88   augment 0.326\n",
            "tick 97    kimg 388.0    time 1h 40m 36s   sec/tick 52.5    sec/kimg 13.12   maintenance 0.1    cpumem 7.80   gpumem 4.90   augment 0.330\n",
            "tick 98    kimg 392.0    time 1h 41m 29s   sec/tick 52.8    sec/kimg 13.20   maintenance 0.0    cpumem 7.80   gpumem 4.91   augment 0.328\n",
            "tick 99    kimg 396.0    time 1h 42m 22s   sec/tick 52.8    sec/kimg 13.20   maintenance 0.0    cpumem 7.80   gpumem 4.87   augment 0.328\n",
            "tick 100   kimg 400.0    time 1h 43m 15s   sec/tick 52.8    sec/kimg 13.20   maintenance 0.0    cpumem 7.80   gpumem 4.91   augment 0.326\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 18.875497095198174}, \"metric\": \"fid50k_full\", \"total_time\": 307.98949241638184, \"total_time_str\": \"5m 08s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000400.pkl\", \"timestamp\": 1670554283.4169424}\n",
            "tick 101   kimg 404.0    time 1h 49m 31s   sec/tick 53.1    sec/kimg 13.27   maintenance 323.6  cpumem 7.81   gpumem 4.85   augment 0.331\n",
            "tick 102   kimg 408.0    time 1h 50m 25s   sec/tick 53.2    sec/kimg 13.29   maintenance 0.0    cpumem 7.81   gpumem 4.88   augment 0.335\n",
            "tick 103   kimg 412.0    time 1h 51m 18s   sec/tick 52.9    sec/kimg 13.23   maintenance 0.0    cpumem 7.81   gpumem 4.86   augment 0.344\n",
            "tick 104   kimg 416.0    time 1h 52m 10s   sec/tick 52.9    sec/kimg 13.23   maintenance 0.0    cpumem 7.81   gpumem 4.86   augment 0.346\n",
            "\n",
            "Aborted!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lMhvOglOqN0-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}